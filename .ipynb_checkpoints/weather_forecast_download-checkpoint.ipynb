{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c9618-11b3-4bbf-b4e2-da18bf09f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#globals().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd574d-728a-4d2e-9a4f-5eae8043862a",
   "metadata": {},
   "source": [
    "## Download GEFS data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded48585-970e-4a4c-8016-9721421562ed",
   "metadata": {},
   "source": [
    "The model used here is Global Ensemble Forecast System (GEFS): https://www.ncei.noaa.gov/products/weather-climate-models/global-ensemble-forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827fb7d-015b-43c8-a4d8-372390e9a1a2",
   "metadata": {},
   "source": [
    "The GEFS model product could be any of the following: \n",
    "- 'atmos.5' - Half degree atmos PRIMARY fields (pgrb2ap5); ~83 most common variables.\n",
    "- 'atmos.5b' - Half degree atmos SECONDARY fields (pgrb2bp5); ~500 least common variables\n",
    "- 'atmos.25' - Quarter degree atmos PRIMARY fields (pgrb2sp25); ~35 most common variables\n",
    "- 'wave' - Global wave products. - 'chem.5'\n",
    "- 'chem.5' - Chemistry fields on 0.5 degree grid\n",
    "- 'chem.25' - Chemistry fields on 0.25 degree grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6e80d-2b9b-4a64-a8ad-531448d4bb05",
   "metadata": {},
   "source": [
    "For our case, following this: https://www.nco.ncep.noaa.gov/pmb/products/gens/, we will need:\n",
    "- From atmos.25, surface: \"sp\", \"tp\", \"sdswrf\", \"sdlwrf\"\n",
    "- From atmos.25, heightAboveGround 2m : \"t2m\", \"d2m\", \"r2\", \"tmax\", \"tmin\", \"u10\", \"v10\", \"tcc\", \"st\", \"soilw\"\n",
    "- From atmos.25, heightAboveGround 10m :\"u10\", \"v10\",  \n",
    "- From atmos.25, atmosphere: \"tcc\"\n",
    "- From atmos.25, depthBelowLandLayer at 0-0.1m: \"st\", \"soilw\"\n",
    "- From atmos.5b, depthBelowLandLayer at 0.1-0.4, 0.4-1, 1-2m: \"st\", \"soilw\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ca3fd-1255-46d0-8211-4f2b4e6a5931",
   "metadata": {},
   "source": [
    "How do the members work? For the atmos output, member 0 is \"c00\", which correspond to the control member, then members 1-30 or \"p01\"-\"p30\". Another option could be 'avg' or 'mean' for the ensemble mean, 'spr' for ensemble spread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95493334-0b2f-4966-998d-4c3b1ba9a940",
   "metadata": {},
   "source": [
    "How does the lead time work? here is represented by fxx in the herbie function, correspond to the perid that is been forecasted, the resolution is every 3 hours for GEFS. For instance, if I need the forecast for the next coming 2 days starting at 30/01/2025, I need to set fxx from 0 to 48 every 3 hours, in python will be range(0, 49, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d85933-7c00-435f-bd8a-e2d648c462e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "from herbie import Herbie\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e27d6c3a-8714-4439-ba61-3e15b39a09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "#initial = datetime.now() - timedelta(days=2)\n",
    "#finish = datetime.now() - timedelta(days=1)\n",
    "#start_date = datetime(initial.year, initial.month, initial.day, 0, 0)\n",
    "#end_date = datetime(finish.year, finish.month, finish.day, 18, 0)\n",
    "start_date = datetime(2023, 3, 12, 0, 0) - timedelta(days=2)\n",
    "end_date = datetime(2023, 3, 22, 0, 0) - timedelta(days=1)\n",
    "member_list = [\"c00\"] + [f\"p{str(i).zfill(2)}\" for i in range(1, 31)]\n",
    "lead_times = range(0, 169, 3)  # Lead times from 0 to 168, every 3 hours = 7 days\n",
    "#variables_surface = [\"sp\", \"tp\", \"sdswrf\", \"sdlwrf\"]\n",
    "variables_surface = [\"tp\"]\n",
    "#variables_2m = [\"t2m\", \"d2m\", \"r2\", \"tmax\", \"tmin\"]\n",
    "variables_2m = [\"t2m\"]\n",
    "#variables_10m = [\"u10\", \"v10\"]\n",
    "#variables_atm = [\"tcc\"]\n",
    "variables_soil = [\"st\", \"soilw\"]\n",
    "#variables_accumulated = [\"tp\", \"sdswrf\", \"sdlwrf\", \"tcc\"]  # Variables to reset at 00:00\n",
    "variables_accumulated = [\"tp\"]  # Variables to reset at 00:00\n",
    "save_dir = \"data/\"\n",
    "#coordinates for Sau Reservoir\n",
    "lat, lon = 41.97, 2.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b4c0677-69f6-442e-b332-8846b247b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty xarray dataset\n",
    "init_dates = np.array([start_date + timedelta(hours=6*i) for i in range(((end_date - start_date).days + 1) * 4)], dtype=\"datetime64[ns]\")\n",
    "dataset = xr.Dataset(\n",
    "    coords={\n",
    "        \"member\": range(0,len(member_list)),\n",
    "        \"init\": init_dates,\n",
    "        \"lead\": range(0,len(lead_times)),\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "051a4e93-6d5c-4c97-8c74-791936bf2afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0,len(lead_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a07d90a-c0c0-4963-bb70-ab4e7be19bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: 2023-03-08 00:00:00 member: c00 lead: 0\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.25\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F00\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.5b\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F00\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "date: 2023-03-08 00:00:00 member: c00 lead: 3\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.25\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F03\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.5b\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F03\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "date: 2023-03-08 00:00:00 member: c00 lead: 6\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.25\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F06\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.5b\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F06\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "date: 2023-03-08 00:00:00 member: c00 lead: 9\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.25\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F09\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.5b\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F09\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "date: 2023-03-08 00:00:00 member: c00 lead: 12\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.25\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F12\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.5b\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F12\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "date: 2023-03-08 00:00:00 member: c00 lead: 15\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.25\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F15\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.5b\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F15\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "date: 2023-03-08 00:00:00 member: c00 lead: 18\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.25\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F18\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n",
      "✅ Found ┊ model=gefs ┊ \u001b[3mproduct=atmos.5b\u001b[0m ┊ \u001b[38;2;41;130;13m2023-Mar-08 00:00 UTC\u001b[92m F18\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mGRIB2 @ aws\u001b[0m ┊ \u001b[38;2;255;153;0m\u001b[3mIDX @ aws\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 75\u001b[0m\n\u001b[1;32m     66\u001b[0m H \u001b[38;5;241m=\u001b[39m Herbie(\n\u001b[1;32m     67\u001b[0m     current_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     68\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgefs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     fxx\u001b[38;5;241m=\u001b[39mlead\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Download the data\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# soil temperature at different depths\u001b[39;00m\n\u001b[1;32m     78\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(path, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfgrib\u001b[39m\u001b[38;5;124m\"\u001b[39m, filter_by_keys\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparamId\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m228139\u001b[39m})  \u001b[38;5;66;03m# st variable\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/herbie/core.py:1045\u001b[0m, in \u001b[0;36mHerbie.download\u001b[0;34m(self, search, searchString, source, save_dir, overwrite, verbose, errors)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# ===============\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# Do the Download\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# ===============\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m search \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;66;03m# Download the full file from remote source\u001b[39;00m\n\u001b[0;32m-> 1045\u001b[0m     \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_reporthook\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m     original_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrib\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrib \u001b[38;5;241m=\u001b[39m outFile\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/urllib/request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[1;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m block \u001b[38;5;241m:=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    269\u001b[0m     read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[1;32m    270\u001b[0m     tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate over initialization dates\n",
    "current_date = start_date\n",
    "c_init = 0\n",
    "while current_date <= end_date:\n",
    "    c_member = 0\n",
    "    for member in member_list:\n",
    "        c_lead = 0\n",
    "        time.sleep(10)\n",
    "        for lead in lead_times:\n",
    "                print(\"date: \" + str(current_date) + \" member: \" + member + \" lead: \" + str(lead))\n",
    "            #try:\n",
    "                # Initialize Herbie for the current date, member, and lead\n",
    "                H = Herbie(\n",
    "                    current_date.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "                    model=\"gefs\",\n",
    "                    product=\"atmos.25\",\n",
    "                    member=member,\n",
    "                    fxx=lead\n",
    "                )\n",
    "                \n",
    "                # Download the data\n",
    "                path = H.download(save_dir=save_dir)\n",
    "\n",
    "                # Initialize a dictionary to hold all data for this combination\n",
    "                data = {}\n",
    "\n",
    "                # Surface variables\n",
    "                ds = xr.open_dataset(path, engine=\"cfgrib\", filter_by_keys={'typeOfLevel': 'surface'})\n",
    "                ds_sel = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "                for var in variables_surface:\n",
    "                    #if var in variables_accumulated and current_date.strftime(\"%H:%M\") == \"00:00\":\n",
    "                    if var in variables_accumulated and lead == 0:\n",
    "                        data[var] = np.array(0, dtype=\"float32\")  # Set accumulated variables to 0\n",
    "                    else:\n",
    "                        data[var] = ds_sel[var].values\n",
    "\n",
    "                # 2m height variables\n",
    "                ds = xr.open_dataset(path, engine=\"cfgrib\", filter_by_keys={'typeOfLevel': 'heightAboveGround', 'level': 2})\n",
    "                ds_sel = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "                for var in variables_2m:\n",
    "                    data[var] = ds_sel[var].values\n",
    "\n",
    "                # 10m height variables\n",
    "                #ds = xr.open_dataset(path, engine=\"cfgrib\", filter_by_keys={'typeOfLevel': 'heightAboveGround', 'level': 10})\n",
    "                #ds_sel = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "                #for var in variables_10m:\n",
    "                #    data[var] = ds_sel[var].values\n",
    "\n",
    "                # Atmosphere variables\n",
    "                #for var in variables_atm:\n",
    "                    #if var in variables_accumulated and current_date.strftime(\"%H:%M\") == \"00:00\":\n",
    "                #    if var in variables_accumulated and lead == 0:\n",
    "                #        data[var] = np.array(0, dtype=\"float32\")  # Set accumulated variables to 0\n",
    "                #    else:\n",
    "                #        ds = xr.open_dataset(path, engine=\"cfgrib\", filter_by_keys={'typeOfLevel': 'atmosphere'})\n",
    "                #        ds_sel = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "                #        data[var] = ds_sel[var].values\n",
    "\n",
    "                # Below-land variables (only for 0-10 cm for soil)\n",
    "                ds = xr.open_dataset(path, engine=\"cfgrib\", filter_by_keys={'typeOfLevel': 'depthBelowLandLayer'})\n",
    "                ds_sel = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "                for var in variables_soil:\n",
    "                    data[var] = ds_sel[var].values\n",
    "\n",
    "                #secondary variables (soil for different depths) at 5 degrees\n",
    "                H = Herbie(\n",
    "                    current_date.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "                    model=\"gefs\",\n",
    "                    product=\"atmos.5b\",\n",
    "                    member=member,\n",
    "                    fxx=lead\n",
    "                )\n",
    "\n",
    "                # Download the data\n",
    "                path = H.download(save_dir=save_dir)\n",
    "\n",
    "                # soil temperature at different depths\n",
    "                ds = xr.open_dataset(path, engine=\"cfgrib\", filter_by_keys={'paramId': 228139})  # st variable\n",
    "                ds_sel = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "                data[\"st_01\"] = ds_sel.sel(depthBelowLandLayer=0.1)['st'].values\n",
    "                data[\"st_04\"] = ds_sel.sel(depthBelowLandLayer=0.4)['st'].values\n",
    "                data[\"st_1\"] = ds_sel.sel(depthBelowLandLayer=1)['st'].values\n",
    "\n",
    "                # Volumetric Soil Moisture Content at different depths\n",
    "                ds = xr.open_dataset(path, engine=\"cfgrib\", filter_by_keys={'paramId': 260185})  # soilw variable\n",
    "                ds_sel = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
    "                data[\"soilw_01\"] = ds_sel.sel(depthBelowLandLayer=0.1)['soilw'].values\n",
    "                data[\"soilw_04\"] = ds_sel.sel(depthBelowLandLayer=0.4)['soilw'].values\n",
    "                data[\"soilw_1\"] = ds_sel.sel(depthBelowLandLayer=1)['soilw'].values\n",
    "\n",
    "                # Append data to the xarray dataset\n",
    "                for var, values in data.items():\n",
    "                    if var not in dataset:\n",
    "                        dataset[var] = ((\"member\", \"init\", \"lead\"), np.full((len(member_list), len(range((end_date - start_date).days + 1))*4, len(lead_times)), np.nan))\n",
    "                    dataset[var][c_member, c_init, c_lead] = values\n",
    "\n",
    "                #os.remove(path)\n",
    "\n",
    "                # Remove the file after processing\n",
    "                #if os.path.exists(path):\n",
    "                    #os.remove(path)\n",
    "\n",
    "                c_lead += 1\n",
    "\n",
    "            #except Exception as e:\n",
    "            #    print(f\"Error processing {current_date} {member} {lead}: {e}\")\n",
    "\n",
    "        c_member += 1\n",
    "    c_init += 1\n",
    "\n",
    "    # Increment the date\n",
    "    current_date += timedelta(hours=6)\n",
    "\n",
    "# Final dataset is now built\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1bfa6e-3e3f-4a3f-b5b9-0d518420638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "dataset.to_netcdf(\"gefs_\"+ str(pd.to_datetime(init_dates[0]).date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "acb6e10d-b182-4e28-9e17-da46713267e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a day to save\n",
    "day_save = \"2025-01-27\"\n",
    "ds_selected = dataset.sel(init=day_save)\n",
    "ds_selected.to_netcdf(\"gefs_\"+ day_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (your_environment_name)",
   "language": "python",
   "name": "your_environment_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
